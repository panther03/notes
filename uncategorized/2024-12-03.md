# Handling exceptions/epochs

Number of epochs required = Number of epoch flips that can occur before the oldest wrong path is fully squashed (i.e. the newest instruction is squashed) + 1.

Simple in-order pipeline: only 1 bit is required, since 1 epoch flip occurs, and then it is not possible to flip the epoch register again before that wrong path is squashed.

This is not a function of pipeline stages; even if there were N instructions along the intial squashed path, if any of them are a branch that attempts to flip the epoch, they would be squashed themselves. Thus, it will only be flipped if the instructions are along the correct path. Since it is in order, wrong path instructions will have already been squashed, and thus only 1 epoch flip can occur before the oldest wrong path is squashed, yielding 2 total epochs => 1 bit.

Asynchronous exceptions complicate this, because the epoch could be flipped at any point. At first glance it makes sense to add more epoch bits according to the number of stages between fetch and execute (indicating the number of cycles => epoch flips that could occur before reaching the epoch check). However, there can be stall cycles due to cache misses or data dependencies.

Maybe this solution is workable with another technique I can't think of, but it seems easier to me to simply check asynchronous exceptions in the same place as branches are checked. This way, it is as though that instruction produced an exception. Whether or not that is actually the case is not important. The logic can be easily integrated into the branch unit. The only thing is that if an exception occurs on a branch instruction, the exception should take priority. but that is a simple detail. 

Since asynchronous exceptions are treated like branches, still only 1 epoch bit is required. This requires once again that a squashed instruction does not flip the epoch, even if there is a pending asynchronous exception. 

The obvious tradeoff with this approach is latency. I don't know if this is the worst case but it's pretty easy to imagine that an exception could happen one cycle after a load miss executes, which represents a pretty big gap between the next time the execute rule is fired.
But I don't think that this latency is very important for asynchronous exceptions. TBD study how it is done in other cores.


The only other wrinkle is synchronous exceptions. These are not known until the complete/commit stage (for in order pipeline it is the same.) For example a load instruction producing an exception from TLB miss. If exceptions are handled in the complete/commit stage, it's not clear to me whether 1 bit is sufficient. This is only adding a delay to the changing of the epoch bit. The same property holds where any instructions down the pipeline would be squashed before any further epoch flips. 

However, I believe using 1 bit relies on the fact that exceptions cannot flip the epoch twice (once in execute and once in writeback; an example would be an async exception that happens while a branch is committed. ). Otherwise, it is trivially false; say the initial epoch is 0, after flipping twice the wrong path instructions are marked as the correct path. 

The choice is between using a 2-bit epoch then and avoiding doing the exception check in the writeback stage under the scenario where that instruction already flipped the epoch in execute.  I have yet to decide which I will implement. 

Finally, when doing the epoch flip in writeback it's also necessary to have a forwarding path to execute (ehr) because that's the only place where the epochs are checked and the squashed bit set. Otherwise, a check could be added in writeback, but I haven't worked out the ramifications of this.

## Dealing with exception critical path

Reading the xr handbook it looks like there is a lot of logic associated with exceptions. Perhaps it is better to have another state in the processor to handle these exceptions.
For now I think I will keep all of this inside the writeback rule, but I will make the ehr & epoch & etc. a register instead of an Ehr. This requires another check in the writeback phase to ensure that squashed instructions are actually dropped.

# XR control registers

Main structure is a Vector of 32 EHRs. 
This is because there are instructions that let you write and read from all control registers. I assume the instructions have a lower priority than the operations in the system that naturally affect these control registers, but this is TBD.

There are two write Methods to this interface. One writes to Vector[i][0] based on the register i out of 32. (Lower priority EHR port). This is the one used by the processor.

The other is a write method that does something specific to that register.
One for each sort of function. I will outline these below

## individual implementations

### RS

Write logic => shift register, overwrite ecause when exception happens
RsExc(Ecause)
Ecause calculated during exception
init to zero

Define structs which are compatible with bits (whatever the trait or Provisos thing is) to do the processor bits
The RS register struct is then 3 of those with the Ecause field in the top.



### WHAMI

init to zero 

### EB 

set by software, read by exception handling 

### EPC

WriteEpc(CurrentPC)
Set during exception handling

### EBADADDR

Set by TLB miss?
or propagated by bus

WriteEBadAddr(Addr)

### TBMISSADR

WriteTbMissAddr(Addr)
can check T bit inside method or outside

### TBPC 

WriteTbPc(pc)
Set during exception handling, same T logic as TBMISSADDR

Read during execution of RFE instruction.

### SCRATCH 

software only

### ITBPTE/DTBPTE

use Callback Method in cache in ControlRegisters interface 
use a simple `if (reg == ITBPTE) then TLB_Callback()`


### ITBTAG/DTBTAG

written by software
read by TLB 

### ITBCTRL

performs different actions depending on bottom 2 bits 
CallBack to TLB
make sure to skip writing to the actual register (or does it matter?)

### ITBADDR/DTBADDR

written during exception handling
lower 22 bits is virtual address of missed
read by software

### random weird T bit effect

Setting T makes the zero register not read as zero


# Memory interface structure

This ISA seems to expose a lot of the cache & tlb subsystem to software. So, it seems like the interface to these modules will be fairly big.

This is informing my approach to organizing the core. I don't like how the cache *and* MMIO logic lives in Core in the original; the interface from the CPU to the outside world should be the bus and a set of interrupts. So I would like the "CPU module" (equivalent of mkPipelined) to have this interface of only Bus.

Now, I wanted to keep CacheInterface in some capacity, because it's cleaner that way; otherwise a bunch of the memory subsystem logic is living inside the CPU core itself, which seems kind of messy. However, then I either have to instantiate the caches and TLBs inside that module, which loses my access from the outside world (I need to pass a method to the ControlRegisters module.) Or, I instantiate them outside, but then have to pass all of them in. And there are more shenanigans because then the CacheInterface module takes control over the bus interface for my CPU.

So I am going with the amittedly kind of messy solution of just putting everything into the VROOM module. There won't be much logic there anyway; it is going to act like sort of a glue module for all the other stages. I think it is fine for this to include the memory subsystem, which includes the logic for redirecting responses from memory to the appropriate place.

# The prefetching scheme is wrong

I had thought the 128-bits word would provide a prefetching scheme. It does not. It will still miss on the request to the next cache line.
That is unless the idea of separating the 32-bit word needed by decode stage with the 128-bit request returned also includes extra logic to always keep *two* 128-bit lines "stocked". It may be more efficient though to just issue the request and drop it. Or to not handle it on the CPU side at all.

I will still keep IMem 128 bits for the sake of the VLIW. Not like it makes a big difference though.

# Flushing pipeline when encountering privileged or control register modifying insns

mips r10k paper says this:

> Instructions that read or modify certain control registers execute serially. The prcoessor can only execute these isntructions, which are mostly restricted to rare cases in the kernel operating system mode, when the pipeline is empty. This restriction has little effect on overall performance.

I am not sure if we need to worry about it on the in order pipeline. The question is if the control registers can only be written after the previous instructions have actually retired. Or if they just need to be read/written in program order, which we would handle fine. IDK

# ISA notes

1. 3 operand isntructions are cringe
2. Full shifter in address generation is cringe

basically just the store instructions

(TODO ISA ISSUES)

# Shifter optimization

To cope with the shifter in address generation noted, perhaps time multiplex one shifter, which takes a full cycle. The result goes back to the address generator or normal ALU, whichever asked for it. This breaks the (potential) critical path and reduces the area to only utilize one shifter. 

Since time multiplexing it this way means every register-relative load/store conflicts with an arithmetic instruction, one final optimization could be to detect when the immediate field is 0. I am not sure how often this comes up in practice. It is worth looking at the output of will's compiler to see.
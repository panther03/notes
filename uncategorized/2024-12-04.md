# pipeline fifo micro optimization

i like the use of the Maybe type to represent the operand register numbers in the decode functions. however, these bits are useless after the decode stage. Presumably the synthesis tool will get rid of them but we may consider removing this representation and adding a separate data structure which removes those fields. TODO in the circuit optimization phase.

# ConfigReg

It *is* the same hardware logic as a normal register, however, it removes the scheduling conflict. Suppose you have a rule A which reads form a register X, and writes to a register Y. rule B writes to X, and reads from the register Y. The expected behavior in hardware is that the reads both happen first, and the writes happen at the end. 

However, Bluespec has to determine a scheduling order for simulation. If either rule fires first, it will read the new value, which is unintended. ConfigReg solves this problem and makes reading and writing conflict free.

Marking either register X or Y as a ConfigReg will add logic to the simulation to store the old value so that the rules can be scheduled conflict free and some order will be chosen. It does not change the hardware.

# Async interrupts take priority?

```c
if (lsic->InterruptPending && (proc->Cr[RS] & RS_INT)) {
    // Interrupts are enabled and there's an interrupt pending, so cause
    // an interrupt exception.

    // N.B. There's an assumption here that the host platform will make
    // writes by other host cores to the interrupt pending flag visible
    // to us in a timely manner, without needing any locking.

    XrBasicInbetweenException(proc, XR_EXC_INT);
}

currentpc = proc->Pc;
proc->Pc += 4;

proc->IFetch = 1;
status = XrReadLong(proc, currentpc, &ir);
proc->IFetch = 0;

if (!status) {
    // The read failed and an exception was caused, so loop and let the
    // exception handler execute.

    continue;
}

// Fetch was successful, decode the instruction word and execute the
// instruction.

XrLowThree[ir & 7](proc, currentpc, ir);
```

maybe x86 is the one that does it weird, but why would device interrupts take priority over internal interrupts? divide by zero, memory exceptions, etc. seems quite weird. i will follow how the emulator does it nonetheless

# Why zero extend for ADD, SUB opcodes?

How do you subtract 1? (decrement register)

# break CR critical path in ALU

use a state register which is set if the instruction matches the privileged type

perform the check over there under that state (1 cycle later)

enq() method is guarded by state != PrivilegeCheck

# Exceptions & control registers

I am redoing my approach to these a little bit, because I have realized some things.

Let's start with control registers. AFAIK, control registers can be written in the following events:

* When an exception is being handled
* When the MTCR instruction is executed
* Asynchronously (?)

I'm not aware of any control registers that actually update asynchronously (or that need to be *handled* asynchronously; CRs like the TLB miss one can probably be updated in the exception handler) at the momnent. However, even if they were to be added (e.g. a counter register) they are easy to handle because they have no notion of program order.

The others are trickier. In particular, the MTCR instruction is problematic. This may be a pathological case but, suppose there is MTCR to set the T bit in RS in the pipeline, then add r0, r0, r0 immediately after. MTCR reaches execute (or writeback; doesn't really matter for this) and sets the CR accordingly. However, decode already ran for add, using the old value of the T bit. I presume this is wrong, although I'm unable to find a spot in the manual that explicitly states the behavior for these control registers.  (TODO ISA ISSUE)

So, CRs need to be accessed in program order. One solution is to create a scoreboard/stall check for these in addition to the registers. But this is a lot of hardware for something which is rarely used. The Mips r10k paper says the instructions that read or write control registers execute serially. So, I am going to copy this philosophy and make the execution serial, somehow. (Although if this is a hot path in kernel code i.e. the TLB miss handlers, maybe this is not so good of an idea. TBD we have to talk to will for this most likely.)

My first idea was to treat these as branch mispredictions; squash all the preceeding instructions and roll back to the PC+4 of the MTCR instruction. In essence when we encounter an MTCR we are speculating that the execution will continue, even though it is always not the case. This has complicated ramifications though. The CR has to be written in either Execute or Commit. If it is written in Execute, at the same time as the epoch is flipped and the PC set back, then the new instructions will see the correct value of the CR, which is great. However, the core does some light reordering, by giving a deeper FIFO to Commit stage, allowing different execution units to overlap. This *should* be correct because the register dependencies are handled nicely already and so are the memory dependencies. The CR dependencies however, are not rolled into this. There is a false hazard in the case that MTCR executes and destroys the value that an instruction waiting in another execution queue would use (let's say a load). 

So, CR writebacks should be delayed until Commit, which represents the architectural commit stage. This solution would carry over nicely to an OOO core. The issue now is that backpressure from the E2W FIFO could mean that the CR is not actually written when the epoch bit flips. Delaying the epoch bit until commit would fix this, but this is adding more complexity to the verification: now epochs can be changed in Execute, Commit, and in the exception handling.

Instead, I am thinking the simplest way to handle this is to simply add another state to the core: serial execution. Decode sets this upon encountering an instruction that requires this property (MTCR). Further decode is blocked until the state is cleared. The MTCR proceeds down the pipeline, and it does not take effect until commit. At this point, the state is cleared, and decode resumes. I suggest this instead of having the instruction drain the rest of the pipeline because technically every instruction accesses the CRs (in decode, to check if the T bit is set).

MFCRs progress down the pipeline as normal. This is because CRs are guaranteed to have been written in program order at the time of any instruction being executed. We can make this guarantee thanks to the way that MTCR is handled which blocks proceeding instructions, as well as the way we handle the next issue: exceptions.

I initially wanted to avoid adding another state for exceptions. The only reason I had initially was to break the critical path in Commit, which I figured would be easier to do just by making all the logic which Commit affects to not use EHR. I would roll asynchronous exception handling into the same logic for synchronous exceptions. However, there is one instruction that (sort of) breaks this: HLT. Halt is supposed to stop the system until the next interrupt (asynchronous, obviously). This *can* still be handled under my scheme, by making the "halt" state spam Decode with NOPs, where the exceptions can then be checked when the NOPs are committed, but this feels like the wrong solution, especially considering it's supposed to be a low power state. Instead I will bite the bullet and add another state for exceptions. Everything is halted in this state. I believe this should ease verification, allow for more extensibility (if exception handling happens over two cycles this is much easier to implement), and add minimal cost for an exception (1 cycle to switch states.) In theory, async exceptions can be read in their own rule, triggering the state to switch to exception handling if detected. 

Now there will be some internal state about exception causes. Before this was coming directly from the E2W fifo. I am thinking the easiest way to represent this in Bluespec is a Reg holding a tagged union. The tagged union corresponds to various exception sources. Async, TLB, Bus error, alignment, Etc. These should translate relatively simply to ECAUSE. 

For asynchronous exceptions, we will need to be careful to drain the pipeline first. Essentially, when an async exception comes in, and we are in steady state, we should immediately enable serial execution mode. Decode maintains a counter as per cem's suggestion. An optimization would be to make this counter only count store instructions that cause problems. A rule is triggered once the counter is 0 and we are in serial execution mode to check the interrupt line again. If it is still high, store the interrupt cause and move to the interrupt handle state. If it is low, go back to normal execution mode.

The interface for the interrupt can probably be an RWire. I don't think it should be a typical bluespec style enqueue or dequeue because that's not how interrupts work.

Note that we have to keep the two serial execution modes separate, I think. Or maintain a separate SerialCause register. This affects how the termination condition is handled. If it is because of MTCR we stop when MTCR is executed, otherwise we stop when the count is 0.

I am being dumb once again when it comes to the external interrupts taking priority. it is an infinite loop; consider the exception check being reordered to after the instruction being executed. it would work the same. in our case we are having the current instruction and the next instruction and the next next and so forth in the pipeline all at once so where we decide to trigger the async one among those that trigger sync exceptions doesnt really matter.

Anyway if a synchronous exception is detected in commit stage simply jump to that state. This does not affect the async logic in any way. It will be checked again once that exception is done being handled.

One last thing. It does not work to add another epoch check to the writeback stage. Reason why is because a proceeding branch instruction which is in execute could flip it and then it would be wrong. Instead we will also drain the pipeline here. The only difference is that the instructions are always squashed in this state. exception handling can probably proceed in parallel, I don't see the issue. As long as commit does not touch anything important. Exception handling is done when the pipeline is drained once again (counter is 0). 

# early exceptions

exceptions generated in fetch due to e.g. misaligned pc should be attached to the instruction early and skip all the crap that comes after
